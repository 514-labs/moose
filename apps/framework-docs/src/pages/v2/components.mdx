# Components Overview

DMv2 is built with modularity in mind. Each component serves a specific purpose and can be used independently or combined into complete pipelines.

## IngestPipeline

The all-in-one solution that combines storage, processing, and ingestion.

```typescript
import { IngestPipeline, Key } from '@514labs/moose-lib';

interface UserEvent {
  id: Key<string>;
  userId: string;
  event: string;
  timestamp: Date;
}

export const userEvents = new IngestPipeline<UserEvent>("user_events", {
  table: true,    // Enable storage
  stream: true,   // Enable processing
  ingest: true    // Create HTTP endpoint
});
```

### Configuration Options

```typescript
{
  // Storage configuration
  table: {
    orderByFields: string[];     // Fields for sorting and indexing
    deduplicate: boolean;        // Enable deduplication
    partitionBy?: string[];     // Custom partitioning
  },

  // Stream processing
  stream: {
    parallelism: number;        // Concurrent processing
    batchSize: number;         // Records per batch
    maxRetries: number;        // Retry attempts
  },

  // HTTP ingestion
  ingest: {
    validateOnly?: boolean;    // Validation without storage
    batchSize?: number;       // Max records per request
  }
}
```

## OlapTable

Type-safe storage optimized for analytical queries.

```typescript
import { OlapTable, Key } from '@514labs/moose-lib';

interface PageView {
  id: Key<string>;
  url: string;
  duration: number;
  timestamp: Date;
}

export const pageViews = new OlapTable<PageView>("page_views", {
  orderByFields: ["url", "timestamp"],
  deduplicate: true
});

// Query with type safety
const results = await pageViews
  .select(["url", "avg(duration) as avgDuration"])
  .where("timestamp > ?", [startDate])
  .groupBy(["url"])
  .orderBy("avgDuration DESC")
  .limit(10)
  .execute();
```

## Stream

Real-time data processing and transformation.

```typescript
import { Stream, Key } from '@514labs/moose-lib';

interface RawEvent {
  id: Key<string>;
  data: string;
}

interface ProcessedEvent {
  id: Key<string>;
  parsedData: object;
  processedAt: Date;
}

export const eventProcessor = new Stream<RawEvent, ProcessedEvent>("event_processor", {
  process: async (event) => ({
    id: event.id,
    parsedData: JSON.parse(event.data),
    processedAt: new Date()
  }),
  parallelism: 2,
  maxRetries: 3
});
```

## IngestApi

HTTP endpoints with automatic validation.

```typescript
import { IngestApi, Key } from '@514labs/moose-lib';

interface Metric {
  id: Key<string>;
  name: string;
  value: number;
  tags: Record<string, string>;
}

export const metricIngestion = new IngestApi<Metric>("metrics", {
  validateOnly: false,  // Store data after validation
  batchSize: 100       // Allow up to 100 records per request
});

// Automatically creates:
// POST /api/ingest/metrics         - Single record
// POST /api/ingest/metrics/batch   - Multiple records
// POST /api/validate/metrics       - Validation only
```

## Component Integration

Components can be used together to build complete pipelines:

```typescript
import { OlapTable, Stream, IngestApi, Key } from '@514labs/moose-lib';

// 1. Define your data types
interface RawMetric {
  id: Key<string>;
  name: string;
  value: string;  // Values come in as strings
}

interface ProcessedMetric {
  id: Key<string>;
  name: string;
  value: number;  // Converted to numbers
  timestamp: Date;
}

// 2. Create storage
const metricStorage = new OlapTable<ProcessedMetric>("metrics", {
  orderByFields: ["name", "timestamp"]
});

// 3. Create processor
const metricProcessor = new Stream<RawMetric, ProcessedMetric>("metric_processor", {
  process: async (metric) => ({
    id: metric.id,
    name: metric.name,
    value: parseFloat(metric.value),
    timestamp: new Date()
  })
});

// 4. Create ingestion endpoint
const metricIngestion = new IngestApi<RawMetric>("metrics");

// 5. Connect components
metricIngestion.pipe(metricProcessor).pipe(metricStorage);
```

## Next Steps

- Learn about [Schema Design](/v2/data-modeling/schemas)
- Explore [Storage with OlapTable](/v2/data-modeling/olap-table)
- Dive into [Stream Processing](/v2/data-modeling/streams)
- Read about [Data Ingestion](/v2/data-modeling/ingestion) 