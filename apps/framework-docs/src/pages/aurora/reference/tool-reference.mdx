---
title: Tool Reference
description: MCP tools and external tools for Aurora
---

import { ArgTable } from "@/components/ArgTable";
import { Heading, HeadingLevel } from "@/components/typography";
import { Callout } from "@/components/callout";
import {
  FeatureCard,
  FeatureGrid,
  Icons,
} from "@/components";

# Tool Reference

Aurora CLI can allow you to use various Aurora MCP tool-sets, as well as install and configure certain external tools. 

Tools are grouped by their purpose into toolsets. Enable the toolsets you want to use by running `aurora config tools` and enabling the tools you want to use. You can also enable tools by adding them to your `mcp.json` file. 

<Callout type="info" title="Performance Tip">
The fewer tools you enable, the higher performance the agent using the tool set will have, especially with respect to tool selection.
</Callout>

## Toolsets

<FeatureGrid columns={4}>
  <FeatureCard
    href="#read-only-moose-tools"
    title="Read Only Moose tools"
    description="Default toolset.
    "
    variant="aurora"
  />
  
  <FeatureCard
    href="#write-moose-tools"
    title="Write Moose tools"
    description="Default toolset.
    "
    variant="aurora"
  />
  
  <FeatureCard
    href="#experimental-remote-clickhouse-tools"
    title="Experimental: Remote ClickHouse Tools"
    description="
    "
    variant="aurora"
  />

  <FeatureCard
    href="#other-experimental-tools"
    title="Other experimental tools"
    description="
    "
    variant="aurora"
  />

</FeatureGrid>

## Read Only Moose tools
Tools needed to read the Moose project and its associated infrastructure.

### Activate this toolset

These tools are enabled by default.

To enable them explicitly, run 
```bash filename="Terminal" copy
aurora config tools
```
and enable `read-only-moose-tools`.
```txt filename="Terminal" copy
? Select experimental tools to enable (no selection defaults to read-only and egress-tools):  
  [x] read-only - Enable read-only tools for data inspection
  [ ] egress-tools - Enable egress-tools for exposing data (requires read only tools: auto enables)
  [ ] experimental-moose-tools - Enable experimental moose tools (requires read only tools: auto enables)
  [ ] remote-clickhouse - Enable Remote Clickhouse integration
  [ ] external-duck-db-mcp - Enable External DuckDB MCP integration
```

If you are managing the Aurora MCP with `mcp.json`, you can enable this toolset by adding the following to your `mcp.json`:

```json filename="MCP.json" copy
"args": [
  ...
  "--read-only", 
  ...
]
```

### When is this toolset useful?
* When you are exploring data in your Moose project: *"Tell me about the data in my Moose project", "Tell me about the data in my `consumption` table"*,  *"Tell me about the data streams in my Moose project"*, *"Describe my DLQ topic"*, *"Tell me about the data in my `enrichment` data stream"*
* When you are expanding, modifying or debugging your Moose project (also requires `write-moose-tools`): *"Did data land in my `consumption` table?", "Did the data in my `consumption` table change?", "Did my materialized view update?"*
* When you want to check the status of your Moose development server, usually whilst debugging new primitive creation (for the second part, also requires `write-moose-tools`): *"Is my Moose development server running?", "Is my Moose development server healthy?", "Did my new workflow kill my local dev server?"*

### Tools

#### `read_moose_project`
Retrieves an infrastructure map from the local Moose development server. Retrieves a list of all primitives in the project (e.g. Data Models, Workflows, Streaming Functions, Materialized Views, APIs), as well as their associated infrastructure (e.g. ClickHouse tables, Redpanda topics, etc.).

#### `read_clickhouse_tables`
Queries local ClickHouse.

#### `read_redpanda_topic`
Reads from local Redpanda. 

#### `check_moose_status`
Checks the status of the Moose project. Useful for debugging.

## Write Moose tools 

Tools needed to create and test Moose primitives. These are used to ingest data, transform data and create egress patterns for data in your project.

### Activate this toolset

These tools are enabled by default (except for in Claude Desktop, where these tools aren't recommended).
These tools require that the `read-only-moose-tools` toolset is enabled.

To enable them explicitly, run 
```bash filename="Terminal" copy
aurora config tools
```
and enable `read-only-moose-tools`.
```txt filename="Terminal" copy
? Select experimental tools to enable (no selection defaults to read-only and egress-tools):  
  [x] read-only - Enable read-only tools for data inspection
  [x] egress-tools - Enable egress-tools for exposing data (requires read only tools: auto enables)
  [ ] experimental-moose-tools - Enable experimental moose tools (requires read only tools: auto enables)
  [ ] remote-clickhouse - Enable Remote Clickhouse integration
  [ ] external-duck-db-mcp - Enable External DuckDB MCP integration
```


If you are managing the Aurora MCP with `mcp.json`, you can enable this toolset by adding the following to your `mcp.json`:

```json filename="MCP.json" copy
"args": [
  ...
  "--moose-tools", 
  ...
]
```
### When is this toolset useful?

* When you are creating new Moose primitives: *"I want to create a new data model for the following API source: ...; documented here: ..."*, *"I want to create a new workflow to ingest data from the following API source: ...; documented here: ..."*, *"I want to create a new streaming function to enrich the data from this data stream with the following API source: ...; documented here: ..."*, *"I want to create a new materialized view that will improve the performance of the `aircraft` API"*
* When you are trying to create a new Moose project: *"I want to create a new Moose project that ingests data from the following API sources: ..., enriches them in stream from the following API: ..., creates a materialized view that ..., and creates egress APIs that allow the following visualizations to be built: ..."*
* When you want to create new data products: *"I want to create a new data product that will allow me to visualize the following data: ...; use the following API sources: ...; create the following materialized views: ...; create and test the performance ofthe following egress APIs: ..."*
* When you want to create new consumption patterns: *"I want to make this data model available for consumption as a stream or an API with the following parameters: ..."*
* When you want to fix upstream data issues: *"Look at my DLQ topic, create a streaming function subscribed to that topic conforming the data to the form expected by the following data model: ..."*
* When you want to improve the performance of your data products: *"Create materialized views that will improve the performance of the following egress APIs: ...", "Look at the chats people are having with my ... data model, create a materialized view that will improve the performance of the dominant query patterns."*

### Usage tips

* Consider the flow of data through your Moose project when creating new primitives. For example, if you want to create a streaming function, the `write_stream_function` tool will have a much better chance of success if there is a data sample, a source and a destination data model in place.
* Many of the tools have testing corollaries (and for the ones that don't, there are general purpose tools that can allow the agent to test the created primitive, like `read_moose_project`, `read_clickhouse_tables`, `read_redpanda_topic`). Use those testing tools to ensure that the agent is doing what you intend it to do.
* Step by step prompting (e.g. "Get sample data from X API", "Create an ingest data model", "Create a workflow to periodically grab data from the API", ...) has a higher success rate than trying to one-shot the entire project creation flow.

### Tools

#### `write_spec`
Generates a plan for an end to end Moose project (from ingest, through transformation and egress). 

Files created:
* *Creates a .md file in the current directory with the plan.*

```txt filename="/project/specification.md" copy
# Technical Specification: ASD-B Aircraft Data Ingestion and Visualization

## 1. Overview

This specification outlines the implementation of a system to ...
```

#### `write_and_run_temp_script`
Creates and runs a temporary script, usually for sampling purposes.

Files created:
* *Creates a temporary script in the /project/.moose/aurora directory, and runs it, usually creating a sample data file in the same directory.*

```js filename="/project/.moose/aurora-scratch/script.js" copy
import fs from 'fs/promises';

const ADSB_API_URL = 'https://api.adsb.lol/v2/mil';
const INGEST_URL = 'http://localhost:4000/ingest/AircraftTransponder';
const FETCH_INTERVAL = 5000; // 5 seconds
const MAX_RUNTIME = 30000; // 30 seconds

async function fetchAndIngestData() {
  const startTime = Date.now();
  const processedAircraft = [];

  while (Date.now() - startTime < MAX_RUNTIME) {
    try {
      // Fetch data from ADSB API
      const response = await fetch(ADSB_API_URL);
      const data = await response.json();
      
      if (data && data.ac && Array.isArray(data.ac)) {
        // Process each aircraft
        for (const aircraft of data.ac) {
          // Ingest aircraft data
          const ingestResponse = await fetch(INGEST_URL, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(aircraft)
          });
          
          if (ingestResponse.ok) {
            processedAircraft.push({
              icao: aircraft.hex,
              timestamp: new Date().toISOString(),
              status: 'ingested'
            });
          }
        }
      }
    } catch (error) {
      // Let errors crash the script
      throw error;
    }

    // Wait for the next interval if we haven't exceeded MAX_RUNTIME
    if (Date.now() - startTime + FETCH_INTERVAL < MAX_RUNTIME) {
      await new Promise(resolve => setTimeout(resolve, FETCH_INTERVAL));
    } else {
      break;
    }
  }

  return {
    totalProcessed: processedAircraft.length,
    processedAircraft,
    startTime: new Date(startTime).toISOString(),
    endTime: new Date().toISOString()
  };
}

// Run the script and write results to output.json
const result = await fetchAndIngestData();
await fs.writeFile('output.json', JSON.stringify(result, null, 2));
```

```json filename="/project/.moose/aurora-scratch/output.json" copy
{
  "ac": [
    {
      "hex": "ae63c1",
      "type": "tisb_icao",
      ...remaining fields
    },
  ]
}
```

#### `write_workflow`
Creates a Moose Workflow, typically run on a schedule, typically used to ingest data. [Moose documentation](../../moose/building/workflows.mdx). 

Files created:
* *Creates a script in the project directory with the workflow, and imports it into `index.ts` or `main.py`.*

```ts filename="/project/script.ts" copy
import { Task, Workflow } from "@514labs/moose-lib";

/**
 * Task to fetch and ingest aircraft transponder data
 */
export const fetchAndIngestAircraftTransponderTask = new Task<{}, TaskResult>("FetchAndIngestAircraftTransponder", {
  run: async () => {
    // Fetch data from external API and ingest into Moose
    // ... see full code above ...
  },
  retries: 3,
  timeout: "1h"
});

/**
 * Workflow to ingest aircraft transponder data
 */
export const ingestAircraftTransponderWorkflow = new Workflow("IngestAircraftTransponder", {
  startingTask: fetchAndIngestAircraftTransponderTask,
  retries: 3,
  timeout: "1h",
  schedule: "@every 5s"
});

/**
 * Default export function that returns the workflow instance
 * Required by the Moose runtime
 */
export default function() {
  return ingestAircraftTransponderWorkflow;
}
```

```ts filename="/project/index.ts" copy
export { ingestAircraftTransponderWorkflow } from "./scripts/IngestAircraftTransponder/IngestAircraftTransponder";
```

Infrastructure created:
* *Creates a Moose managed temporal script, orchestrating the workflow that was created.*

#### `run_workflow`
Runs a Moose workflow. Used as part of the `write_workflow` flow. [Moose documentation](../../moose/building/workflows.mdx).

#### `write_data_model`
Creates a Moose data model, typically used to define the schema of the data in your Moose project. [Moose documentation](../../moose/building/data-models.mdx). 

Files created:
* *Creates a data model in the project directory, and imports it into `index.ts` or `main.py`.*

```ts filename="/project/<data-model-name>.ts" copy
// Define aircraft tracking data interface
export interface AircraftTrackingData {
  hex: string;           // Unique aircraft identifier
  flight: string;        // Flight number
  lat: number;          // Latitude
  lon: number;          // Longitude
  alt_baro: number;     // Barometric altitude
  gs: number;           // Ground speed
  track: number;        // Heading
  timestamp: Date;      // Observation time
  // ... other fields
}

// Define ingest pipelines
export const AircraftTrackingDataPipeline = new IngestPipeline<AircraftTrackingData>(
  "AircraftTrackingData", 
  { table: false, stream: true, ingest: true }
);
```

```ts filename="/project/index.ts" copy
export * from "./datamodels/models";
```

Infrastructure created:
* *Depending on the configuration, creates a ClickHouse table, a Redpanda topic, and/or an ingest API.*

#### `write_stream_function`
Creates a Moose stream processing function. Runs on a per row basis as data is ingested into the stream. [Moose documentation](../../moose/building/streaming-functions.mdx). 

Files created:
* *Creates a stream function in the project directory, and imports it into `index.ts` or `main.py`.*

```ts filename="/project/<stream-function-name>.ts" copy

// Transform raw aircraft data to processed format
function transformAircraft(record: AircraftTrackingData): AircraftTrackingProcessed {
  const zorderCoordinate = calculateZOrder(record.lat, record.lon);
  const navFlags = parseNavModes(record.nav_modes);
  
  return {
    ...record,
    zorderCoordinate,
    ...navFlags,
    timestamp: new Date(record.timestamp),
  };
}

// Connect the data pipeline
AircraftTrackingDataPipeline.stream!.addTransform(
  AircraftTrackingProcessedPipeline.stream!,
  transformAircraft
);
```

```ts filename="/project/index.ts" copy
export * from "./functions/process_aircraft";
```

Infrastructure created:
* *Creates a streaming function.*

#### `write_materialized_view`
Creates a Moose materialized view. [Moose documentation](../../moose/building/materialized-views.mdx). 

Files created:
* *Creates a materialized view in the project directory, and imports it into `index.ts` or `main.py`.*

```ts filename="/project/<materialized-view-name>.ts" copy
// Define schema for aggregated aircraft data near San Francisco
interface AircraftTrackingProcessed_NearbySFSchema {
  hex: string;
  last_seen: string & Aggregated<"max", [Date]>;
  count: string & Aggregated<"count", []>;
  avg_lat: string & Aggregated<"avg", [number]>;
  avg_lon: string & Aggregated<"avg", [number]>;
}

// SQL query to find aircraft within 50 miles of San Francisco
const query = sql`
  SELECT 
    hex, 
    maxState(timestamp) as last_seen, 
    countState() as count, 
    avgState(lat) as avg_lat, 
    avgState(lon) as avg_lon 
  FROM ${AircraftTrackingProcessedPipeline.table!} 
  WHERE ((3959 * 2) * ASIN(SQRT(
    POWER(SIN(RADIANS(37.7749 - lat) / 2), 2) + 
    (COS(RADIANS(lat)) * COS(RADIANS(37.7749)) * 
     POWER(SIN(RADIANS(-122.4194 - lon) / 2), 2))
  ))) <= 50 
  GROUP BY hex
`;

// Create materialized view for efficient querying
export const AircraftTrackingProcessed_NearbySF = new MaterializedView<AircraftTrackingProcessed_NearbySFSchema>({
  selectStatement: query,
  selectTables: [AircraftTrackingProcessedPipeline.table!],
  tableName: "aircraft_tracking_processed_nearby_sf",
  materializedViewName: "AircraftTrackingProcessed_NearbySF",
  engine: ClickHouseEngines.AggregatingMergeTree,
  orderByFields: ["hex"]
});
```

```ts filename="/project/index.ts" copy
export * from './views/AircraftTrackingProcessed_NearbySF';
```

Infrastructure created:
* *Creates a materialized view in ClickHouse.*

#### `create_egress_api`
Creates an egress API from Moose ClickHouse. Can utilize type safe parameters. [Moose documentation](../../moose/building/egress-apis.mdx). 

Files created:
* *Creates an egress API in the project directory, and imports it into `index.ts` or `main.py`.*  

```ts filename="/project/<egress-api-name>.ts" copy
import { ConsumptionApi } from "@514labs/moose-lib";
import { tags } from "typia";

interface AircraftRadiusParams {
  lat: number; // Center latitude
  lon: number; // Center longitude
  radius: number; // Search radius in miles
}

export const getAircraftWithinRadius = new ConsumptionApi<AircraftRadiusParams>(
  "getAircraftWithinRadius",
  async (params, { client, sql }) => {
    // Execute the query using the Haversine formula to calculate distances
    const result = await client.query.execute(sql`
      SELECT * 
      FROM AircraftTrackingProcessed 
      WHERE (3959 * 2 * ASIN(SQRT(POWER(SIN(RADIANS(${params.lat} - lat) / 2), 2) + 
            COS(RADIANS(lat)) * COS(RADIANS(${params.lat})) * 
            POWER(SIN(RADIANS(${params.lon} - lon) / 2), 2)))) <= ${params.radius}
    `);
    
    return result;
  },
  {
    metadata: {
      description: "Returns all aircraft within a given radius (in miles) of a specified latitude and longitude"
    }
  }
);
```

```ts filename="/project/index.ts" copy
export * from './apis/getAircraftWithinRadius';
```

Infrastructure created:
* *Creates an egress API.*

#### `test_egress_api`
Tests the specified APIs. Used as part of the `create_egress_api` flow.

## Experimental: Remote ClickHouse Tools  (Alpha)

Tools for reading data in your external ClickHouse database (e.g. those hosted in Boreal or ClickHouse Cloud). These are useful for iterating off a production project, for debugging production issues or for local testing of changes to production data.

<Callout type="warning" title="Read-only credentials">
  For an abundance of caution, we suggest using read-only credentials for this toolset. [ClickHouse documentation](https://clickhouse.com/docs/operations/access-rights). If you want to modify your ClickHouse database, we suggest using Moose to do so.
</Callout>

### Activate this toolset

These tools are **not** enabled by default.
To enable them explicitly, run `aurora config tools` and enable `remote-clickhouse`. If you use `aurora config tools` to enable this toolset, you will still need to manually add the environment variables to your `mcp.json` file.

If you are managing the Aurora MCP with `mcp.json`, you can enable this toolset by adding the following to your `mcp.json`:

```json filename="MCP.json" copy
"args": [
  ...
  "--remote-clickhouse", 
  ...
]
"env": {
  ...
  "BOREAL_CLICKHOUSE_HOST": "...",
  "BOREAL_CLICKHOUSE_PORT": "...",
  "BOREAL_CLICKHOUSE_USER": "...",
  "BOREAL_CLICKHOUSE_PASSWORD": "...",
  "BOREAL_CLICKHOUSE_DATABASE": "...",
}
```
## Other Experimental Tools

These tools are in research preview, [let us know if you are interested in using them](mailto:aurora@fiveonefour.com).

### Experimental: Context management tools (Research Preview)
Tools for managing context related to your Moose project. 

Useful for:

- testing your data infrastructure against policy (e.g. data quality, data security, data governance)
- ensuring metrics definition standardization for ad hoc queries of your data

If you are interested in using these tools, please contact us at [support@moose.ai](mailto:aurora@fiveonefour.com).

### Experimental: External tools (Research Preview)
Tools for interacting with external data systems.

Current supported external data systems:

- DuckDB
- Databricks

If you are interested in using these tools, or any other external data tools, please contact us at [support@moose.ai](mailto:aurora@fiveonefour.com).