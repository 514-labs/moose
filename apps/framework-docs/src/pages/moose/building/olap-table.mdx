---
title: OLAP Tables
description: OLAP Tables for Moose
---

import { Callout, BulletPointsCard, CheckmarkBullets, LanguageSwitcher, TypeScript, Python } from "@/components";
import { Tabs } from "nextra/components";

# Database Tables
<LanguageSwitcher />
Tables are the foundation of Moose's data storage layer, designed to integrate with your entire data pipeline. They store data ingested from your APIs and streams while powering your analytics queries for your downstream transformations, APIs, and more.

## Overview

Tables in Moose provide a type-safe way to define your database schema directly in your code, eliminating the tedious database administration tasks that typically interrupt your development flow.

<BulletPointsCard
title="Working with OLAP Tables"
bullets={[
  {
    title: "Define your table schema as a data model",
    description: "Create a type definition that describes your table structure"
  },
  {
    title: "Instantiate your table",
    description: "Create a typed table instance from your model with one line of code"
  },
  {
    title: "Configure storage options",
    description: "Optionally specify indexing, ordering, and other optimizations for your query patterns"
  },
  {
    title: "Iterate on your schema",
    description: "Add, edit, or remove fields and tables update automatically"
  }
]}
/>

### Basic Example

<TypeScript>
```ts filename="FirstTable.ts" copy
interface MyFirstTable {
  id: Key<string>;
  name: string;
  age: number;
}

// Create a table named "first_table"
const myTable = new OlapTable<MyFirstTable>("first_table");
```
</TypeScript>

<Python>
```py filename="FirstTable.py" copy
from pydantic import BaseModel
from moose_lib import Key, OlapTable
from pydantic import BaseModel

class MyFirstTable(BaseModel):
    id: Key[str]
    name: str
    age: int

# Create a table named "first_table"
my_table = OlapTable[MyFirstTable]("first_table") 

```
</Python>


<CheckmarkBullets
  title="Benefits:"
  bullets={[
    "Boilerplate CREATE/ALTER TABLE statements handled for you",
    "Automatic type mapping between your code and database types",
    "Built-in validation before storage"
  ]}
/>

## Creating Tables
There are two main approaches to creating tables:
- [Standalone Tables](#standalone-tables)
- [Tables in Ingestion Pipelines](#tables-in-ingestion-pipelines)

<Tabs items={["IngestPipelines (Recommended)", "Standalone Tables"]}>
<Tabs.Tab title="IngestPipelines (Recommended)">
### Creating Tables in Ingestion Pipelines

For end-to-end data flows, create tables as part of an ingestion pipeline:

<TypeScript>
```ts filename="PipelineTable.ts"
import { IngestPipeline, Key } from "@514labs/moose-lib";

// Define your schema
interface UserEvent {
  id: Key<string>;
  userId: string;
  timestamp: Date;
  eventType: string;
}

// Create a complete ingestion pipeline with a table
const eventsPipeline = new IngestPipeline<UserEvent>("user_events", {
  ingest: true,    // Creates a REST API endpoint at POST localhost:4000/ingest/user_events
  stream: true,    // Creates Kafka/Redpanda topic
  table: {         // Creates and configures the table named "user_events"
    orderByFields: ["id", "timestamp"],
    deduplicate: true
  }
});

// Access the table component when needed
const eventsTable = eventsPipeline.table;
```
</TypeScript>

<Python>
```py filename="PipelineTable.py"
from moose_lib import IngestPipeline, Key, OlapTable
from pydantic import BaseModel

class UserEvent(BaseModel):
    id: Key[str]
    user_id: str
    timestamp: Date
    event_type: str

events_pipeline = IngestPipeline[UserEvent]("user_events", {
  ingest: True, # Creates a REST API endpoint at POST localhost:4000/ingest/user_events
  stream: True, # Creates a Kafka/Redpanda topic
  table: {      # Creates and configures the table named "user_events"
    orderByFields: ["id", "timestamp"],
    deduplicate: True
  }
})

# Access the table component when needed:
events_table = events_pipeline.get_table()
```
</Python>

This integrated approach automatically creates the necessary infrastructure and connects all components, ensuring data flows smoothly from API to database with full type checking at every step.

</Tabs.Tab>

<Tabs.Tab title="Standalone Tables">

Create a table directly for custom data flows or when you need fine-grained control:

<TypeScript>
```ts filename="StandaloneTable.ts"
import { OlapTable, Key } from "@514labs/moose-lib";

// Define your schema
interface ExampleSchema {
  id: Key<string>;
  dateField: Date;
  numericField: number;
  booleanField: boolean;
  floatField: number;
  integerField: number & tags.Type<"int64">; // Moose supports native tagged types so you can use Integers in typescript
}

// Create a standalone table named "example_table"
const exampleTable = new OlapTable<ExampleSchema>("example_table", {
  orderByFields: ["id", "dateField"], // Optional when using a primary key
  deduplicate: true  // Optional: keep only the latest version of each record
});

// Now you can:
// - Write to this table from streams
// - Query it directly
// - Use it as a source for materialized views
```
</TypeScript>

<Python>
```py filename="StandaloneTable.py"
from moose_lib import Key, OlapTable
from pydantic import BaseModel

class ExampleSchema(BaseModel):
    id: Key[str]
    date_field: Date
    numeric_field: float
    boolean_field: bool

# Create a standalone table named "example_table"
example_table = OlapTable[ExampleSchema]("example_table", {
  orderByFields: ["id", "date_field"],
  deduplicate: True
})
```
</Python>

<BulletPointsCard
  divider={false}
  bulletStyle="check"
  title="Use Standalone Tables When:"
  bullets={[
    "Use when you need to do a bulk import of data",
    "Use when you have in-memory ETL/ELT workflows that need to write directly to a table as opposed to a streaming ingestion pipeline",
    "Use when you have some external service that is maintaining and writing to the table, like a CDC or other external ETL service"
  ]}
/>

</Tabs.Tab>
</Tabs>

## Querying Tables

<TypeScript>
Moose provides a `sql` tagged template literal function that you can use to write SQL queries on your tables, which supports interpolation of table names, column names, and values.
</TypeScript>

<Python>
Moose lets you define `f` strings that you can use to write SQL queries on your tables, which supports interpolation of table names, column names, and values.
</Python>

This is useful for:
- Transforming your data in your database and saving the results as regular views or [materialized views](/moose/materialized-views).
- Querying tables from your [Consumption API route handlers](/moose/consumption-api) to expose your data to client applications that are running outside of Moose.



<TypeScript>
```ts filename="QueryingTables.ts"
import { sql } from "@514labs/moose-lib";

interface MyTableSchema {
  id: Key<string>;
  name: string;
  value: number;
}

const myTable = new OlapTable<MyTableSchema>("my_table");
const cols = myTable.columns;
const query = sql`
  SELECT ${cols.id}, ${cols.name}, ${cols.value} FROM ${myTable}
`;

// When Moose runs this query, it will automatically convert the interpolated values into the correct SQL syntax for your database:
// SELECT id, name, value FROM my_table
```

This lets you write SQL that feels like TypeScript - get autocomplete for your table columns and catch typos at dev time instead of waiting for runtime.
</TypeScript>

<Python>
```py filename="QueryingTables.py"
from moose_lib import MooseClient, OlapTable, Key

class MyTableSchema(BaseModel):
    id: Key[str]
    name: str
    value: int

my_table = OlapTable[MyTableSchema]("my_table")

client = MooseClient()

query = client.query.execute(
  f"SELECT id, name, value FROM {my_table.name}" # Use a variable to interpolate the table name
)
```
</Python>


## Configuring Table Indexes

You must configure table indexing using one of these approaches:
1. Define at least one `Key` in your table schema
2. Specify `orderByFields` in the table config
3. Use both (all `Key` fields must come first in the `orderByFields` array)

<TypeScript>
```ts filename="PrimaryKeyConfig.ts"
import { OlapTable, Key } from '@514labs/moose-zlib';

// Approach 1: Using primary key only
interface Record1 {
  id: Key<string>;  // Primary key field
  field1: string;
  field2: number;
}

const table1 = new OlapTable<Record1>("table1");  // id is the primary key
```
</TypeScript>

<Python>
```py filename="PrimaryKeyConfig.py"
from moose_lib import Key, OlapTable
from pydantic import BaseModel

class Record1(BaseModel):
    id: Key[str] # Primary key field
    field1: str
    field2: int

table1 = OlapTable[Record1]("table1") # id is the primary key
```
</Python>

### Order By Fields Only

<TypeScript>
```ts filename="OrderByFieldsOnly.ts"
// Approach 2: Using orderByFields only
interface SchemaWithoutPrimaryKey {
  field1: string;
  field2: number;
  field3: Date;
}

const tableWithOrderByFieldsOnly = new OlapTable<SchemaWithoutPrimaryKey>("table2", {
  orderByFields: ["field1", "field2"]  // Specify ordering without primary key
});
```
</TypeScript>

<Python>
Leverage the `OlapTableConfig` class to configure your table:

```py filename="OrderByFieldsOnly.py" copy
from moose_lib import Key, OlapTable, OlapTableConfig
from pydantic import BaseModel
from datetime import datetime

class SchemaWithoutPrimaryKey(BaseModel):
    field1: str
    field2: int
    field3: datetime

table2 = OlapTable[SchemaWithoutPrimaryKey]("table2", OlapTableConfig(
  orderByFields=["field1", "field2"] # Specify ordering without primary key
))
```
</Python>

### Using Both Primary Key and Order By Fields

<TypeScript>
```ts filename="ComboKeyAndOrderByFields.ts" copy
// Approach 3: Using both (primary key must be first)
interface SchemaWithKey {
  id: Key<string>;  // Primary key field
  field1: string;
  field2: number;
}

const tableWithKeyAndOrderByFields = new OlapTable<SchemaWithKey>("table3", {
  orderByFields: ["id", "field1"]  // Primary key must be first
});
```
</TypeScript>

<Python>
```py filename="ComboKeyAndOrderByFields.py" copy
from moose_lib import Key, OlapTable, OlapTableConfig
from pydantic import BaseModel

class SchemaWithKey(BaseModel):
    id: Key[str]
    field1: str
    field2: int

table3 = OlapTable[SchemaWithKey]("table3", OlapTableConfig(
  orderByFields=["id", "field1"] # Primary key must be first
))
```
</Python>

### Using Multiple Primary Keys

<TypeScript>
```ts filename="MultiKeyTable.ts" copy
interface MultiKeyRecord {
  key1: Key<string>;
  key2: Key<number>;
  field1: string;
}

const multiKeyTable = new OlapTable<MultiKeyRecord>("multi_key_table", {
  orderByFields: ["key1", "key2", "field1"]  // Multiple keys must come first
});
```
</TypeScript>

<Python>
```py filename="MultiKeyTable.py" copy
from moose_lib import Key, OlapTable, OlapTableConfig
from pydantic import BaseModel

class MultiKeyRecord(BaseModel):
    key1: Key[str]
    key2: Key[int]
    field1: str

multi_key_table = OlapTable[MultiKeyRecord]("multi_key_table", OlapTableConfig(
  orderByFields=["key1", "key2", "field1"] # Multiple keys must come first
))
```
</Python>

### Deduplication
Keep only the latest record per key:

<TypeScript>
```ts filename="DeduplicatedTable.ts" copy
const table = new OlapTable<Record>("table", {
  orderByFields: ["id"],
  deduplicate: true
});
```
</TypeScript> 

<Python>
```py filename="DeduplicatedTable.py" copy
from moose_lib import Key, OlapTable, OlapTableConfig

class Record(BaseModel):
    id: Key[str]

table = OlapTable[Record]("table", OlapTableConfig(
  orderByFields=["id"],
  deduplicate=True
))
```
</Python>

<Callout type="warning" title="Deduplication Caveats">
Deduplication uses ClickHouse's ReplacingMergeTree engine for eventual deduplication, meaning duplicate records may not be removed immediately. This process can take time and is not guaranteed to be immediate. For more details, see the [ClickHouse documentation](https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replacingmergetree).
</Callout>

### Invalid Configurations

<TypeScript>
```ts filename="InvalidConfig.ts" copy
// Error: No primary key or orderByFields
interface BadRecord1 {
  field1: string;
  field2: number;
}
const badTable1 = new OlapTable<BadRecord1>("bad_table1");

// Error: Primary key not first in orderByFields
interface BadRecord2 {
  id: Key<string>;
  field1: string;
}
const badTable2 = new OlapTable<BadRecord2>("bad_table2", {
  orderByFields: ["field1", "id"]  // Wrong order - primary key must be first
});

// Error: Nullable field in orderByFields
interface BadRecord3 {
  id: Key<string>;
  field1: string;
  field2?: number;
}
const badTable3 = new OlapTable<BadRecord3>("bad_table3", {
  orderByFields: ["id", "field2"]  // Can't have nullable field in orderByFields
});
```
</TypeScript>

<Python>
```py filename="InvalidConfig.py"
from moose_lib import Key, OlapTable, OlapTableConfig
from typing import Optional

class BadRecord1(BaseModel):
    field1: str
    field2: int

bad_table1 = OlapTable[BadRecord1]("bad_table1") ## No primary key or orderByFields

class BadRecord2(BaseModel):
    id: Key[str]
    field1: str

bad_table2 = OlapTable[BadRecord2]("bad_table2", OlapTableConfig(
  orderByFields=["field1", "id"] # Wrong order - primary key must be first
))

class BadRecord3(BaseModel):
    id: Key[str]
    field1: str
    field2: Optional[int]

bad_table3 = OlapTable[BadRecord3]("bad_table3", OlapTableConfig(
  orderByFields=["id", "field2"] # Can't have nullable field in orderByFields
))
```
</Python>

## Direct Data Insertion

The `OlapTable` provides an `insert()` method that allows you to directly insert data into ClickHouse tables with validation and error handling.

### Basic Insert Operations

<TypeScript>
```ts filename="DirectInsert.ts" copy
import { OlapTable, Key } from "@514labs/moose-lib";

interface UserEvent {
  id: Key<string>;
  userId: string;
  timestamp: Date;
  eventType: string;
}

const eventsTable = new OlapTable<UserEvent>("user_events");

// Insert single record or array of records
const result = await eventsTable.insert([
  { id: "evt_1", userId: "user_123", timestamp: new Date(), eventType: "click" },
  { id: "evt_2", userId: "user_456", timestamp: new Date(), eventType: "view" }
]);

console.log(`Successfully inserted: ${result.successful} records`);
console.log(`Failed: ${result.failed} records`);
```
</TypeScript>

<Python>
```py filename="DirectInsert.py" copy
from moose_lib import OlapTable, Key, InsertOptions
from pydantic import BaseModel
from datetime import datetime

class UserEvent(BaseModel):
    id: Key[str]
    user_id: str
    timestamp: datetime
    event_type: str

events_table = OlapTable[UserEvent]("user_events")

# Insert single record or array of records
result = events_table.insert([
    {"id": "evt_1", "user_id": "user_123", "timestamp": datetime.now(), "event_type": "click"},
    {"id": "evt_2", "user_id": "user_456", "timestamp": datetime.now(), "event_type": "view"}
])

print(f"Successfully inserted: {result.successful} records")
print(f"Failed: {result.failed} records")
```
</Python>

### Validation Methods

Before inserting data, you can validate it using the following methods:

<TypeScript>
```ts filename="ValidationMethods.ts" copy
// Type guard with compile-time type narrowing
if (eventsTable.isValidRecord(unknownData)) {
  // TypeScript now knows unknownData is UserEvent
  console.log(unknownData.userId); // Type-safe access
}

// Detailed validation with error reporting
const validationResult = eventsTable.validateRecord(unknownData);
if (validationResult.success) {
  console.log("Valid data:", validationResult.data);
} else {
  console.log("Validation errors:", validationResult.errors);
}

// Assert validation (throws on failure)
try {
  const validData = eventsTable.assertValidRecord(unknownData);
  // Use validData with full type safety
} catch (error) {
  console.log("Validation failed:", error.message);
}
```
</TypeScript>

<Python>
```py filename="ValidationMethods.py" copy
from moose_lib import OlapTable, Key
from pydantic import BaseModel

class UserEvent(BaseModel):
    id: Key[str]
    user_id: str
    event_type: str

events_table = OlapTable[UserEvent]("user_events")

# Validate a single record
validated_data, error = events_table.validate_record(unknown_data)
if validated_data is not None:
    print("Valid data:", validated_data)
else:
    print("Validation error:", error)

# Validate multiple records with detailed error reporting
validation_result = events_table.validate_records(data_array)
print(f"Valid records: {len(validation_result.valid)}")
print(f"Invalid records: {len(validation_result.invalid)}")
for error in validation_result.invalid:
    print(f"Record {error.index} failed: {error.error}")
```
</Python>

### Error Handling Strategies

Choose from three error handling strategies based on your reliability requirements:

#### Fail-Fast Strategy (Default)
<TypeScript>
```ts filename="FailFast.ts" copy
// Stops immediately on any error
const result = await eventsTable.insert(data, {
  strategy: 'fail-fast'
});
```
</TypeScript>

<Python>
```py filename="FailFast.py" copy
from moose_lib import InsertOptions

# Stops immediately on any error
result = events_table.insert(data, InsertOptions(strategy="fail-fast"))
```
</Python>

#### Discard Strategy
<TypeScript>
```ts filename="Discard.ts" copy
// Discards invalid records, continues with valid ones
const result = await eventsTable.insert(data, {
  strategy: 'discard',
  allowErrors: 10,           // Allow up to 10 failed records
  allowErrorsRatio: 0.05     // Allow up to 5% failure rate
});
```
</TypeScript>

<Python>
```py filename="Discard.py" copy
from moose_lib import InsertOptions

# Discards invalid records, continues with valid ones
result = events_table.insert(data, InsertOptions(
    strategy="discard",
    allow_errors=10,           # Allow up to 10 failed records
    allow_errors_ratio=0.05    # Allow up to 5% failure rate
))
```
</Python>

#### Isolate Strategy
<TypeScript>
```ts filename="Isolate.ts" copy
// Retries individual records to isolate failures
const result = await eventsTable.insert(data, {
  strategy: 'isolate',
  allowErrorsRatio: 0.1
});

// Access detailed failure information
if (result.failedRecords) {
  result.failedRecords.forEach(failed => {
    console.log(`Record ${failed.index} failed: ${failed.error}`);
  });
}
```
</TypeScript>

<Python>
```py filename="Isolate.py" copy
from moose_lib import InsertOptions

# Retries individual records to isolate failures
result = events_table.insert(data, InsertOptions(
    strategy="isolate",
    allow_errors_ratio=0.1
))

# Access detailed failure information
if result.failed_records:
    for failed in result.failed_records:
        print(f"Record {failed.index} failed: {failed.error}")
```
</Python>

### Stream Support

<TypeScript>
For large datasets, use Node.js streams for memory-efficient processing:
```ts filename="StreamInsert.ts" copy
import { Readable } from 'node:stream';

const dataStream = new Readable({
  objectMode: true,
  read() {
    // Stream implementation
  }
});

const result = await eventsTable.insert(dataStream, {
  strategy: 'fail-fast'  // Note: 'isolate' not supported with streams
});
```
</TypeScript>

<Python>
For large datasets, use Python generators for memory-efficient processing:

```py filename="StreamInsert.py" copy
def user_event_generator():
    """Generate user events for memory-efficient processing."""
    for i in range(10000):
        yield {
            "id": f"evt_{i}",
            "user_id": f"user_{i % 100}",
            "timestamp": datetime.now(),
            "event_type": "click" if i % 2 == 0 else "view"
        }

# Insert from generator (validation not available for streams)
result = events_table.insert(user_event_generator(), InsertOptions(strategy="fail-fast"))
```
</Python>

### Performance Optimization

The insert API includes several performance optimizations:

- **Memoized connections**: ClickHouse clients are reused across insert calls
- **Batch processing**: Optimized batch sizes for large datasets
- **Async inserts**: Automatic async insert mode for datasets > 1000 records
- **Connection management**: Use `close_client()` when completely done

<TypeScript>
```ts filename="Performance.ts" copy
// For high-throughput scenarios
const result = await eventsTable.insert(largeDataset, {
  validate: false,  // Skip validation for performance
  strategy: 'discard'
});

// Clean up when completely done (optional)
await eventsTable.closeClient();
```
</TypeScript>

<Python>
```py filename="Performance.py" copy
from moose_lib import InsertOptions

# For high-throughput scenarios
result = events_table.insert(large_dataset, InsertOptions(
    validate=False,  # Skip validation for performance
    strategy="discard"
))

# Clean up when completely done (optional)
events_table.close_client()
```
</Python>

## Development Workflow

### Local Development with Hot Reloading

One of the powerful features of Moose is its integration with the local development server:

1. Start your local development server with `moose dev`
2. When you define or modify an `OlapTable` in your code and save the file:
   - The changes are automatically detected
   - The TypeScript compiler plugin processes your schema definitions
   - The infrastructure is updated in real-time to match your code changes
   - Your tables are immediately available for testing

For example, if you add a new field to your schema:

<TypeScript>
```ts filename="HotReloading.ts" copy
// Before
interface BasicSchema {
  id: Key<string>;
  name: string;
}

// After adding a field
interface BasicSchema {
  id: Key<string>;
  name: string;
  createdAt: Date;  // New field
}
```
</TypeScript>

<Python>
```py filename="HotReloading.py" copy
# Before
class BasicSchema(BaseModel):
    id: Key[str]
    name: str

# After adding a field
class BasicSchema(BaseModel):
    id: Key[str]
    name: str
    created_at: datetime
```
</Python>

The Moose framework will:
1. Detect the change when you save the file
2. Update the table schema in the local ClickHouse instance
3. Make the new field immediately available for use

### Verifying Your Tables

You can verify your tables were created correctly using:
```bash filename="Terminal" copy
# List all tables in your local environment
moose ls
```

#### Connecting to your local ClickHouse instance
You can connect to your local ClickHouse instance with your favorite database client. Your credentials are located in your `.moose/config.toml` file:

```toml filename=".moose/config.toml" copy
[clickhouse_config]
db_name = "local"
user = "panda"
password = "pandapass"
use_ssl = false
host = "localhost"
host_port = 18123
native_port = 9000
```



