import { Tabs, Steps, Card, FileTree } from "nextra/components";
import { Callout, FeatureCard, FeatureGrid, ToggleBlock, ZoomImg, Python, TypeScript, LanguageSwitcher, MuxVideo, BulletPointsCard } from "@/components";
import { Database, FileCode, Download, Zap } from "lucide-react";

# Start With Your ClickHouse Database

<LanguageSwitcher />

Bootstrap a Moose project directly from your existing ClickHouse database in minutes.


<Callout type="info" title="Early Access Feature">
We're actively developing this feature and would love your feedback. While it's ready for most use cases, check out [Known Limitations](#known-limitations) for details on what's still in progress.
</Callout>


## Why Use Moose with ClickHouse?

ClickHouse is a blazingly-fast analytical database, but with the power comes complexity and a lot of manual work:

<BulletPointsCard
  title="Manually Managing ClickHouse?"
  bulletStyle="x"
  bullets={[
    {
      title: "Copy-pasting DDL between environments",
      description: "Running the same CREATE TABLE and CREATE MATERIALIZED VIEW statements in dev, staging, and prod, hoping you didn't miss a field",
    },
    {
      title: "Forgetting dependency order",
      description: "Creating a materialized view before its source table exists, then scrambling to figure out what broke",
    },
    {
      title: "Lost schema changes",
      description: "That ALTER TABLE you ran last week? Good luck remembering what it was when you need to apply it to production",
    },
  ]}
/>

Moose provides a code layer on top of your existing ClickHouse database.

<BulletPointsCard
  bulletStyle="check"
  divider={false}
  title="How Moose Can Speed Things Up:"
  bullets={[
    {
      title: "Reduce boilerplate",
      description: "Generate typed models from your existing tables instead of hand-coding everything",
    },
    {
      title: "Build APIs in code, not Jinja templates",
      description: "Write TypeScript/Python functions with proper IDE support instead of templated SQL",
    },
    {
      title: "Add streaming with one line of code",
      description: "Turn any table into a real-time streaming destination without configuring Kafka topics, serialization, or message schemas",
    },
    {
      title: "Version control your database",
      description: "Manage schema changes, materialized views, and transformations like actual code",
    },
    {
      title: "Leverage CI/CD built for ClickHouse",
      description: "See a plan for your database changes before promoting to production, and apply them automatically when you do",
    },
  ]}
/>

## Quick Setup
<Callout type="info" title="Prerequisites">
<TypeScript>
- **Node.js**: [version 20+](https://nodejs.org/en/download) (LTS recommended)
</TypeScript>

<Python>
- **Python**: [version 3.12+](https://www.python.org/downloads/) 
</Python>

- **OS**: macOS or Linux (WSL supported for Windows)
- **Docker Desktop/Engine**: [24.0.0+](https://docs.docker.com/get-started/get-docker/)
- **Access to ClickHouse Database**: Connection URL with credentials
</Callout>

<Steps>

### Get Your ClickHouse Connection String

You need a ClickHouse connection URL. Format looks like this:

```
http://username:password@host:port/?database=database_name
```

<Callout type="info" title="Try with ClickHouse Playground">
Want to test without your own ClickHouse? Use the [ClickHouse Playground](https://clickhouse.com/docs/getting-started/playground) with the connection string above. It has sample datasets (read-only) you can experiment with.

```txt copy
https://explorer:@play.clickhouse.com:443/?database=default
```

</Callout>


<ToggleBlock openText="Need help finding credentials?" closeText="Hide credential help">
<Tabs items={["ClickHouse Cloud", "Self-Hosted", "Docker"]}>
<Tabs.Tab>
1. Log into your [ClickHouse Cloud console](https://clickhouse.cloud/)
2. Go to your service details page
3. Find "Connect" or "Connection Details" section
4. Copy the HTTPS endpoint and your username/password
</Tabs.Tab>
<Tabs.Tab>
- Check your ClickHouse config file (usually `/etc/clickhouse-server/config.xml`)
- Look for `<http_port>` (default: 8123) and `<https_port>` (default: 8443)
- Check users config in `/etc/clickhouse-server/users.xml` or users.d/ directory
- Default user is often `default` with no password
</Tabs.Tab>
<Tabs.Tab>
- Check your docker-compose.yml or docker run command for environment variables
- Look for `CLICKHOUSE_USER`, `CLICKHOUSE_PASSWORD`, `CLICKHOUSE_DB`
- Default is usually `http://default:@localhost:8123/?database=default`
</Tabs.Tab>
</Tabs>
</ToggleBlock>

<ToggleBlock openText="Common Issues" closeText="Hide Common Issues">

- **Can't connect?** Try `curl http://your-host:8123/ping` to test connectivity
- **Authentication failed?** Verify username/password with `clickhouse-client --user=username --password=password`
- **Database not found?** Run `SHOW DATABASES` to see available databases
- **Permission denied?** Check user permissions with `SHOW GRANTS FOR username`

**Still stuck?** Check the [ClickHouse documentation](https://clickhouse.com/docs/en/getting-started/install) for your specific deployment method.

</ToggleBlock>


### Install Moose & Bootstrap Your Project

Install Moose if you haven't already:
```bash copy
# Install Moose
bash -i <(curl -fsSL https://fiveonefour.com/install.sh) moose
```

Create a new project:
<Python>
```bash copy
# Bootstrap from your ClickHouse database
moose init my-project --from-remote <YOUR_CLICKHOUSE_CONNECTION_STRING> --language python

# Set up dependencies
cd my-project
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
</Python>

<TypeScript>
```bash copy
# Bootstrap from your ClickHouse database
moose init my-project --from-remote <YOUR_CLICKHOUSE_CONNECTION_STRING> --language typescript

# Set up dependencies
cd my-project
npm install
```
</TypeScript>

### Start Your Local Environment

```bash copy
moose dev
```

This spins up your entire data stack locally and generates typed models from your ClickHouse tables.

### Check What Got Generated

Moose created data models for each of your ClickHouse tables. Check <Python inline>`app/main.py`</Python><TypeScript inline>`app/index.ts`</TypeScript> to see what you got.

<Python>
<FileTree>
<FileTree.Folder name="app" defaultOpen>
<FileTree.File name="main.py" />
</FileTree.Folder>
<FileTree.File name="moose.config.toml" />
<FileTree.File name="requirements.txt" />
<FileTree.File name="setup.py" />
</FileTree>
</Python>

<TypeScript>
<FileTree>
<FileTree.Folder name="app" defaultOpen>
<FileTree.File name="index.ts" />
</FileTree.Folder>
<FileTree.File name="moose.config.toml" />
<FileTree.File name="package.json" />
</FileTree>
</TypeScript>

</Steps>

## Type Mapping

Moose automatically maps ClickHouse data types to appropriate language-specific types:

<Python>

| ClickHouse Type | Python Type | Notes |
|-----------------|-------------|-------|
| `String` | `str` | |
| `Int8`, `Int16`, `Int32`, `Int64` | `int` | With size annotations |
| `UInt8`, `UInt16`, `UInt32`, `UInt64` | `int` | With size annotations |
| `Float32`, `Float64` | `float` | With precision annotations |
| `Decimal(P,S)` | `Decimal` | With precision/scale |
| `Date`, `Date32` | `date` | |
| `DateTime`, `DateTime64` | `datetime` | With precision for DateTime64 |
| `Array(T)` | `list[T]` | Nested type mapping |
| `UUID` | `UUID` | |
| `Boolean` | `bool` | |
| `Nullable(T)` | `Optional[T]` | |
| `LowCardinality(T)` | `T` | Maps to base type |
| `JSON` | `any` | Partial support |

</Python>
<TypeScript>

| ClickHouse Type | TypeScript Type | Notes |
|-----------------|-----------------|-------|
| `String` | `string` | |
| `Int8`, `Int16`, `Int32`, `Int64` | `number` | |
| `UInt8`, `UInt16`, `UInt32`, `UInt64` | `number` | |
| `Float32`, `Float64` | `number` | |
| `Decimal(P,S)` | `number` | |
| `Date`, `Date32` | `Date` | |
| `DateTime`, `DateTime64` | `Date` | |
| `Array(T)` | `T[]` | Nested type mapping |
| `UUID` | `string` | |
| `Boolean` | `boolean` | |
| `Nullable(T)` | `T \| null` | |
| `LowCardinality(T)` | `T` | Maps to base type |
| `JSON` | `Record<string, any>` | Partial support |

</TypeScript>

## What's Next?

Now that you've got Moose talking to your ClickHouse database:

### 1. Get Some Data Locally

```bash copy
# CLI command to seed from remote ClickHouse
moose seed from-remote-clickhouse <YOUR_CLICKHOUSE_CONNECTION_STRING> --rows 100
```

### 2. Build Materialized Views That Don't Break

<ToggleBlock openText="See how Moose fixes common ClickHouse pain points" closeText="Hide details">

**The ClickHouse Reality:**

```sql
-- Step 1: Create target table (remember the exact schema!)
CREATE TABLE daily_user_stats (
    user_id UInt64,
    date Date,
    event_count UInt64
) ENGINE = MergeTree()
ORDER BY (user_id, date);

-- Step 2: Create materialized view (hope you got the dependency order right!)
CREATE MATERIALIZED VIEW daily_user_stats_mv TO daily_user_stats AS
SELECT 
    user_id,
    toDate(timestamp) as date,
    count(*) as event_count
FROM user_events 
GROUP BY user_id, date;

-- Step 3: Copy-paste this to staging... then production... 
-- Step 4: Pray you didn't miss anything when the schema changes
-- Step 5: Remember to DROP VIEW before changing SELECT logic
```

**With Moose:**

<TypeScript>
```typescript
import { userEvents } from "./tables"; // Import existing tables
import { MaterializedView, sql } from "@514labs/moose-lib";

// Define your target schema
interface DailyUserStats {
  user_id: number;
  date: Date;
  event_count: number;
}

// Define what you want - Moose generates all the DDL
const dailyStats = new MaterializedView<DailyUserStats>({
  // âœ… SQL in actual code, directly reference table names and columns for autocompletion
  selectStatement: sql`
    SELECT 
      ${userEvents.user_id}, 
      toDate(${userEvents.timestamp}) as date, 
      count(*) as event_count
    FROM ${userEvents} 
    GROUP BY ${userEvents.user_id}, date
  `,
  selectTables: [userEvents],
  tableName: "daily_user_stats",
  materializedViewName: "daily_user_stats_mv",
  orderByFields: ["user_id", "date"]
});

// Moose automatically:
// âœ… Creates the target table with correct schema
// âœ… Sets up the materialized view 
// âœ… Handles dependency order
// âœ… Manages schema migrations
// âœ… Provides hot-reload in development
```
</TypeScript>

<Python>
```python
from moose_lib import MaterializedView, OlapTable, MaterializedViewOptions
from pydantic import BaseModel
from datetime import date
from app.tables import user_events ## Import existing tables

## Define your target schema
class DailyUserStats(BaseModel):
    user_id: int
    date: date  
    event_count: int


# Define what you want - Moose generates all the DDL
daily_stats = MaterializedView[DailyUserStats](
    MaterializedViewOptions(
        select_statement="""
            SELECT user_id, toDate(timestamp) as date, count(*) as event_count
            FROM user_events GROUP BY user_id, date
        """,
        select_tables=[user_events],
        table_name="daily_user_stats",
        materialized_view_name="daily_user_stats_mv",
        order_by_fields=["user_id", "date"]
    )
)

# Moose automatically:
# âœ… Creates the target table with correct schema  
# âœ… Sets up the materialized view
# âœ… Handles dependency order
# âœ… Manages schema migrations
# âœ… Provides hot-reload in development
```
</Python>

</ToggleBlock>

**Ready to dive deeper?** â†’ [Materialized Views docs](/moose/building/materialized-views)

### 3. Build APIs That Handle the Annoying Stuff
Consumption APIs are a way to write native <TypeScript inline>TypeScript</TypeScript><Python inline>Python</Python> functions that wrap your ClickHouse queries and make them available for your frontend clients via a type-safe REST API.

They are designed to take care of the boilerplate that slows you down like:
- Request validation
- Response type mapping
- SQL injection protection
- Documentation
- JWT validation (if you're using it)

<ToggleBlock openText="Example code" closeText="Hide details">
<TypeScript>
```typescript
import { ConsumptionApi } from "@514labs/moose-lib";
import { tags } from "typia";

interface GetUserStatsParams {
  userId: number;                            // âœ… Automatic validation
  startDate: string & tags.Format<"date">;   // âœ… Automatic validation  
  endDate: string & tags.Format<"date">;     // âœ… Automatic validation
}

interface GetUserStatsResponse {
  date: string;
  event_count: number;
}

export const UserStatsApi = new ConsumptionApi<GetUserStatsParams, GetUserStatsResponse[]>(
  "user-stats",
  async ({ userId, startDate, endDate }, { client, sql }) => {
    const query = sql`
      SELECT date, event_count 
      FROM daily_user_stats 
      WHERE user_id = ${userId} 
        AND date BETWEEN ${startDate} AND ${endDate}
      ORDER BY date
    `;

    const data = await client.query.execute<GetUserStatsResponse>(query);
    return await data.json();
  }
);

// Moose automatically provides:
// âœ… Request validation based on TypeScript types
// âœ… Response type mapping to your target schema
// âœ… SQL injection protection  
// âœ… OpenAPI documentation generation
// âœ… JWT validation (if configured)
// âœ… IDE autocompletion for table names
```
</TypeScript>

<Python>
```python
from moose_lib import ConsumptionApi, MooseClient
from pydantic import BaseModel
from datetime import date

class GetUserStatsParams(BaseModel):
    user_id: int           # âœ… Automatic validation
    start_date: date       # âœ… Automatic validation
    end_date: date         # âœ… Automatic validation

class GetUserStatsResponse(BaseModel):
    date: date
    event_count: int

def get_user_stats(client: MooseClient, params: GetUserStatsParams):
    query = f"""
        SELECT date, event_count 
        FROM daily_user_stats 
        WHERE user_id = {params.user_id} 
          AND date BETWEEN '{params.start_date}' AND '{params.end_date}'
        ORDER BY date
    """
    return client.query.execute(query)

api = ConsumptionApi[GetUserStatsParams, GetUserStatsResponse](
    name="user-stats", 
    query_function=get_user_stats
)

# Moose automatically provides:
# âœ… Request validation based on Pydantic models
# âœ… Response type mapping to your target schema
# âœ… SQL injection protection
# âœ… OpenAPI documentation generation  
# âœ… JWT validation (if configured)
# âœ… IDE autocompletion for table names
```
</Python>

</ToggleBlock>

**Ready to dive deeper?** â†’ [Consumption APIs docs](/moose/building/consumption-apis)

### 4. Use AI to Generate Analytics & APIs

Want AI to generate insights and APIs from your data? Try [Aurora](/aurora/quickstart) - our AI analytics agent for Moose projects.

## Current Limitations

### What we're working on adding:
- **Selective table import**: Imports all tables (filtering coming soon)
- **Default values**: Adding annotations to your models to set default values for your tables
- **Advanced ClickHouse types**:
  - `Map(K, V)` types
  - `Tuple(T1, T2, ...)` types  
  - `Geo` types (Point, Ring, Polygon, etc.)

<Callout type="warning" title="Tables with these types will be skipped">
Right now, tables featuring these types will be skipped during the initialization process.
</Callout>

### Known Limitations

#### Supported Types with Manual Type Adjustments:

#### `LowCardinality(T)` 
Currently, `LowCardinality(T)` maps to base type `T`.

You can override the autogenerated data models by making the following adjustments to fields that are `LowCardinality` in your generated code:

<TypeScript>
You can add LowCardinality optimization by using intersection types:
```typescript
interface MyModel {
  status: string & LowCardinality; // Optimized for low cardinality
  category: string;                // Regular string
}
```
</TypeScript>

<Python>
LowCardinality is automatically applied to `Literal` types:
```python
from typing import Literal

class MyModel(BaseModel):
    status: Literal["active", "inactive", "pending"]  # Automatically 
    category: str                                     # Regular string
```
</Python>

#### `JSON` types 
<Python>
Maps to `any` 
</Python>

<TypeScript>
Maps to `Record<string, any>`
</TypeScript>

#### `Enum` types
Enum column types that have an empty string as a key will be skipped:

```sql
CREATE TABLE my_table (
    my_enum Enum8(""=0, "A"=1, "B"=2)
);
```

```python
## This does not work:
class my_enum(StringToEnumMixin, IntEnum):
    "" = 0 ## Illegal to have an empty string as a key
    A = 1
    B = 2

## Instead what will be generated is:
class my_enum(StringToEnumMixin, IntEnum):
    = 0 ## Will lead to a type error, consider using a different key
    A = 1
    B = 2
```

<Python>
In Python, using a numeric key in a string enum will lead to a type error:
```sql
CREATE TABLE my_table (
    my_enum Enum8("1"=0, "A"=1, "B"=2)
);
```

```python
class my_enum(StringToEnumMixin, IntEnum):
    1 = 0 ## Will lead to a type error, consider using a different key
    A = 1
    B = 2
```
</Python>